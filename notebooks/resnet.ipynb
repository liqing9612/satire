{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "b9Y6nasKCuFT",
    "outputId": "59ec9594-4f59-40fb-88a0-1a8bd0d87ec7"
   },
   "outputs": [],
   "source": [
    "!gcloud auth login\n",
    "!mkdir /content/images/\n",
    "!gsutil -mq cp -r gs://lily-li-dataset/satire/defaults/images/ /content/images/\n",
    "!gsutil -mq cp gs://lily-li-dataset/satire/defaults/**.jsonl /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "XAfPxpq1DKQ9",
    "outputId": "2c610c19-e059-4069-96ec-18ca3810e2ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jsonlines\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "with jsonlines.open('/content/train.jsonl', 'r') as data:\n",
    "    hl_train = []\n",
    "    img_train = []\n",
    "    y_train = []\n",
    "    for d in data:\n",
    "        try:\n",
    "            filepath = \"/content/images/images/\" + str(d[\"id\"]) + \".jpg\"  \n",
    "            img = Image.open(filepath).resize((128,128), Image.BICUBIC).convert('RGB')\n",
    "            img_train.append(np.asarray(img) / 255.)\n",
    "            hl_train.append(d[\"text\"])\n",
    "            y_train.append(d[\"label\"])\n",
    "        except:\n",
    "            print(\"Image at filepath {0} does not exist\".format(filepath))\n",
    "\n",
    "with jsonlines.open('/content/test.jsonl', 'r') as data:\n",
    "    hl_test = []\n",
    "    img_test= []\n",
    "    y_test = []\n",
    "    for d in data:\n",
    "        try:\n",
    "            filepath = \"/content/images/images/\" + str(d[\"id\"]) + \".jpg\"  \n",
    "            img = Image.open(filepath).resize((128,128), Image.BICUBIC).convert('RGB')\n",
    "            img_test.append(np.asarray(img) / 255.)\n",
    "            hl_test.append(d[\"text\"])\n",
    "            y_test.append(d[\"label\"])\n",
    "        except:\n",
    "            print(\"Image at filepath {0} does not exist\".format(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWM2ICM3G_0l"
   },
   "outputs": [],
   "source": [
    "img_train = np.stack(img_train, axis=0)\n",
    "img_test = np.stack(img_test, axis=0)\n",
    "\n",
    "img_train = tf.convert_to_tensor(img_train)\n",
    "img_test = tf.convert_to_tensor(img_test)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tV0oQjZDDNdu"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    ResNet = tf.keras.applications.ResNet101(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=(128,128,3),\n",
    "            )\n",
    "\n",
    "    input_img = tf.keras.layers.Input(shape=(128,128,3))\n",
    "    img_output = ResNet(input_img)\n",
    "    flattened = tf.keras.layers.Flatten()(img_output)\n",
    "\n",
    "    dense = tf.keras.layers.Dense(256, activation='relu')(flattened)\n",
    "    dropout = tf.keras.layers.Dropout(0.5)(dense)\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(dense)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "        inputs=input_img,\n",
    "        outputs=output,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "id": "mQl4OKvnDPYL",
    "outputId": "868e589a-8d34-4fe5-89aa-ac978146caf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet101 (Functional)       (None, 4, 4, 2048)        42658176  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 51,047,297\n",
      "Trainable params: 50,941,953\n",
      "Non-trainable params: 105,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeGzt5mwDQU2"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=2e-5)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=[\"accuracy\", \"AUC\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "colab_type": "code",
    "id": "pBLKZmweDRUZ",
    "outputId": "bb0fb8ee-5fd3-4981-b09f-6bb8dfbbecd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "250/250 [==============================] - 57s 228ms/step - loss: 0.7163 - accuracy: 0.6609 - auc: 0.6965 - precision: 0.5831 - recall: 0.5378 - val_loss: 1.7813 - val_accuracy: 0.6008 - val_auc: 0.5162 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/15\n",
      "250/250 [==============================] - 54s 218ms/step - loss: 0.1314 - accuracy: 0.9703 - auc: 0.9954 - precision: 0.9714 - recall: 0.9538 - val_loss: 0.8914 - val_accuracy: 0.5272 - val_auc: 0.5094 - val_precision: 0.4083 - val_recall: 0.4104\n",
      "Epoch 3/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0409 - accuracy: 0.9960 - auc: 0.9998 - precision: 0.9966 - recall: 0.9934 - val_loss: 0.9846 - val_accuracy: 0.5998 - val_auc: 0.6069 - val_precision: 0.4964 - val_recall: 0.1717\n",
      "Epoch 4/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0209 - accuracy: 0.9986 - auc: 0.9998 - precision: 0.9988 - recall: 0.9978 - val_loss: 0.7354 - val_accuracy: 0.7132 - val_auc: 0.7672 - val_precision: 0.6609 - val_recall: 0.5783\n",
      "Epoch 5/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0114 - accuracy: 0.9995 - auc: 1.0000 - precision: 0.9991 - recall: 0.9997 - val_loss: 0.7722 - val_accuracy: 0.7233 - val_auc: 0.7982 - val_precision: 0.6605 - val_recall: 0.6313\n",
      "Epoch 6/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0070 - accuracy: 0.9996 - auc: 1.0000 - precision: 0.9997 - recall: 0.9994 - val_loss: 0.8045 - val_accuracy: 0.7258 - val_auc: 0.8020 - val_precision: 0.6787 - val_recall: 0.5947\n",
      "Epoch 7/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0057 - accuracy: 0.9996 - auc: 1.0000 - precision: 0.9997 - recall: 0.9994 - val_loss: 0.8297 - val_accuracy: 0.7354 - val_auc: 0.8028 - val_precision: 0.6857 - val_recall: 0.6225\n",
      "Epoch 8/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0040 - accuracy: 0.9996 - auc: 1.0000 - precision: 0.9994 - recall: 0.9997 - val_loss: 0.8677 - val_accuracy: 0.7314 - val_auc: 0.8023 - val_precision: 0.6637 - val_recall: 0.6629\n",
      "Epoch 9/15\n",
      "250/250 [==============================] - 54s 218ms/step - loss: 0.0028 - accuracy: 0.9999 - auc: 1.0000 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.8906 - val_accuracy: 0.7354 - val_auc: 0.8022 - val_precision: 0.6696 - val_recall: 0.6654\n",
      "Epoch 10/15\n",
      "250/250 [==============================] - 54s 218ms/step - loss: 0.0023 - accuracy: 0.9998 - auc: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 0.9101 - val_accuracy: 0.7334 - val_auc: 0.8038 - val_precision: 0.6706 - val_recall: 0.6528\n",
      "Epoch 11/15\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.0018 - accuracy: 0.9999 - auc: 1.0000 - precision: 1.0000 - recall: 0.9997 - val_loss: 0.9520 - val_accuracy: 0.7339 - val_auc: 0.7995 - val_precision: 0.6769 - val_recall: 0.6376\n",
      "Epoch 12/15\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0013 - accuracy: 0.9999 - auc: 1.0000 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.7349 - val_auc: 0.8036 - val_precision: 0.6778 - val_recall: 0.6402\n",
      "Epoch 13/15\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0011 - accuracy: 0.9999 - auc: 1.0000 - precision: 1.0000 - recall: 0.9997 - val_loss: 0.9806 - val_accuracy: 0.7324 - val_auc: 0.8032 - val_precision: 0.6662 - val_recall: 0.6604\n",
      "Epoch 14/15\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0013 - accuracy: 0.9998 - auc: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 1.0227 - val_accuracy: 0.7314 - val_auc: 0.7961 - val_precision: 0.6837 - val_recall: 0.6086\n",
      "Epoch 15/15\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.0014 - accuracy: 0.9998 - auc: 1.0000 - precision: 0.9997 - recall: 0.9997 - val_loss: 1.0729 - val_accuracy: 0.7354 - val_auc: 0.7906 - val_precision: 0.6921 - val_recall: 0.6073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd704287b8>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=img_train, y=y_train, batch_size=32, epochs=15, validation_steps=2000//32, steps_per_epoch=8000//32,\n",
    "           validation_data=(img_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "satire_resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
