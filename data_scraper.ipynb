{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onion_image_url(link):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    r = requests.get(link, headers=hdr)\n",
    "    data = r.text  #Get the website source as text\n",
    "    soup = BeautifulSoup(data) #Setup a \"soup\" which BeautifulSoup can search\n",
    "    vals =  soup.findAll(attrs={\"name\":\"twitter:image\"})\n",
    "    for v in vals:\n",
    "        if v[\"content\"] not in (\"https://x.kinja-static.com/assets/images/logos/placeholders/theonion.png\", ):\n",
    "            return v[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hp_image_url(link):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0'}\n",
    "    r = requests.get(link, headers=hdr)\n",
    "    data = r.text  #Get the website source as text\n",
    "    soup = BeautifulSoup(data) #Setup a \"soup\" which BeautifulSoup can search\n",
    "    vals = soup.findAll(attrs={\"property\":\"og:image:url\"})\n",
    "    for v in vals:\n",
    "        if v[\"content\"] not in (\"https://img.huffingtonpost.com/asset/default-entry.jpg?ops=1778_1000\"):\n",
    "            return v[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sarcasm_Headlines_Dataset_v2.json', 'r') as handle:\n",
    "    json_data = [json.loads(line) for line in handle]\n",
    "    for i, d in enumerate(json_data):\n",
    "        try:\n",
    "            link = d[\"article_link\"]\n",
    "            if d[\"is_sarcastic\"] == 1:\n",
    "                image_link = get_onion_image_url(link)\n",
    "                urllib.request.urlretrieve(image_link, \"satire_images/\" + str(i) + \".jpg\")\n",
    "            else:\n",
    "                image_link = get_hp_image_url(link)\n",
    "                urllib.request.urlretrieve(image_link, \"serious_images/\" + str(i) + \".jpg\")\n",
    "            json_data[i][\"has_image\"] = True\n",
    "        except:\n",
    "            json_data[i][\"has_image\"] = False\n",
    "\n",
    "with open(\"dataset_with_images.json\", \"w\") as outfile: \n",
    "    json.dump(json_data, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
