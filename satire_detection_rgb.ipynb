{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14714 images belonging to 2 classes.\n",
      "Found 3678 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, rescale = 1./255, horizontal_flip = True)\n",
    "\n",
    "train_generator = generator.flow_from_directory(r\"data\\satire\\satire_images_rgb\",\n",
    "                                      target_size = (128,128),\n",
    "                                      class_mode = 'categorical',\n",
    "                                      interpolation = 'bicubic',\n",
    "                                      batch_size = 32,\n",
    "                                      subset = \"training\")\n",
    "\n",
    "val_generator = generator.flow_from_directory(r\"data\\satire\\satire_images_ela\",\n",
    "                                      target_size = (128,128),\n",
    "                                      class_mode = 'categorical',\n",
    "                                      interpolation = 'bicubic',\n",
    "                                      batch_size = 32,\n",
    "                                      subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SATIRE_DETECTOR(input_shape=(128,128,3)):\n",
    "    X_input = Input(input_shape)\n",
    "    ##########################################################\n",
    "    X = Conv2D(32, (5,5), padding=\"valid\", activation=tf.nn.leaky_relu, name=\"conv1\")(X_input)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), name=\"max_pool1\")(X)\n",
    "    \n",
    "    X = Conv2D(32, (5,5), padding=\"valid\", activation=tf.nn.leaky_relu, name=\"conv2\")(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), name=\"max_pool2\")(X)\n",
    "    X = Dropout(0.25, name=\"dropout1\")(X)\n",
    "    ###########################################################\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(256, activation=tf.nn.leaky_relu, name=\"fc1\", kernel_regularizer=l2(0.0005), bias_regularizer=l2(0.0005))(X)\n",
    "    X = Dropout(0.5, name=\"dropout2\")(X)\n",
    "    \n",
    "    X = Dense(2, activation=\"softmax\", name=\"fc2\")(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=X_input, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SATIRE_DETECTOR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pool1 (MaxPooling2D)     (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 58, 58, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pool2 (MaxPooling2D)     (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 26912)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               6889728   \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 6,918,306\n",
      "Trainable params: 6,918,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9, decay=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "459/459 [==============================] - 327s 713ms/step - loss: 0.8236 - accuracy: 0.5487 - val_loss: 0.7378 - val_accuracy: 0.5573\n",
      "Epoch 2/10\n",
      "459/459 [==============================] - 298s 649ms/step - loss: 0.7448 - accuracy: 0.5631 - val_loss: 0.7150 - val_accuracy: 0.5759\n",
      "Epoch 3/10\n",
      "459/459 [==============================] - 397s 865ms/step - loss: 0.7190 - accuracy: 0.5685 - val_loss: 0.7137 - val_accuracy: 0.5636\n",
      "Epoch 4/10\n",
      "459/459 [==============================] - 420s 916ms/step - loss: 0.7169 - accuracy: 0.5759 - val_loss: 0.7258 - val_accuracy: 0.5751\n",
      "Epoch 5/10\n",
      "459/459 [==============================] - 409s 892ms/step - loss: 0.7327 - accuracy: 0.5747 - val_loss: 0.7178 - val_accuracy: 0.5718\n",
      "Epoch 6/10\n",
      "459/459 [==============================] - 312s 679ms/step - loss: 0.7225 - accuracy: 0.5753 - val_loss: 0.7405 - val_accuracy: 0.5507\n",
      "Epoch 7/10\n",
      "459/459 [==============================] - 288s 627ms/step - loss: 0.7419 - accuracy: 0.5736 - val_loss: 0.7452 - val_accuracy: 0.5888\n",
      "Epoch 8/10\n",
      "459/459 [==============================] - 313s 682ms/step - loss: 0.7570 - accuracy: 0.5760 - val_loss: 0.7422 - val_accuracy: 0.5735\n",
      "Epoch 9/10\n",
      "459/459 [==============================] - 507s 1s/step - loss: 0.7483 - accuracy: 0.5751 - val_loss: 0.7385 - val_accuracy: 0.5620\n",
      "Epoch 10/10\n",
      "459/459 [==============================] - 532s 1s/step - loss: 0.7673 - accuracy: 0.5776 - val_loss: 0.7606 - val_accuracy: 0.5600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x188ec965ba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=32\n",
    "model.fit(train_generator,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=val_generator,\n",
    "          steps_per_epoch=14714//batch_size,\n",
    "          validation_steps=3678//batch_size,\n",
    "          workers=1,\n",
    "          use_multiprocessing=False\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(r\"checkpoints\\satire_detection_rgb\\final_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
