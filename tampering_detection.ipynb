{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mM8IRt_1_mYH",
    "outputId": "76f4f00c-6af4-4610-f147-c09290c7ac5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Add, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "outputs": [],
   "source": [
    "## Uncomment to convert images to ELA\n",
    "\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# from pylab import *\n",
    "# import re\n",
    "# from PIL import Image, ImageChops, ImageEnhance\n",
    "\n",
    "# def convert_to_ela_image(path, quality):\n",
    "#     filename = path\n",
    "#     resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n",
    "#     ELA_filename = filename.split('.')[0] + '.ela.png'\n",
    "    \n",
    "#     im = Image.open(filename).convert('RGB')\n",
    "#     im.save(resaved_filename, 'JPEG', quality=quality)\n",
    "#     resaved_im = Image.open(resaved_filename)\n",
    "    \n",
    "#     ela_im = ImageChops.difference(im, resaved_im)\n",
    "    \n",
    "#     extrema = ela_im.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     if max_diff == 0:\n",
    "#         max_diff = 1\n",
    "#     scale = 255.0 / max_diff\n",
    "    \n",
    "#     ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n",
    "    \n",
    "#     os.remove(resaved_filename)\n",
    "    \n",
    "#     return ela_im\n",
    "\n",
    "# for directory in (r\"data\\CASIA\\CASIA_rgb\\Au\", r\"data\\CASIA\\CASIA_rgb\\Tp\"):\n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.endswith(\".jpg\"):\n",
    "#             file_path = os.path.join(directory, filename)\n",
    "#             pil_image = convert_to_ela_image(file_path, 90)\n",
    "#             pil_image.save(\"data\\CASIA\\CASIA_ela\\\" + directory.split(\"\\\\\")[-1] + \"\\\\\" + filename.split(\".\")[0] + \".png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10049 images belonging to 2 classes.\n",
      "Found 2511 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2, rescale = 1./255, horizontal_flip = True)\n",
    "\n",
    "\n",
    "train_generator = generator.flow_from_directory(r\"data\\CASIA\\CASIA_ela\",\n",
    "                                          target_size = (128,128),\n",
    "                                          class_mode = \"categorical\", \n",
    "                                          interpolation = \"nearest\",\n",
    "                                          batch_size = batch_size,\n",
    "                                          subset = \"training\")\n",
    "\n",
    "val_generator = generator.flow_from_directory(r\"data\\CASIA\\CASIA_ela\",\n",
    "                                          target_size = (128,128),\n",
    "                                          class_mode = \"categorical\",\n",
    "                                          interpolation = \"nearest\",\n",
    "                                          batch_size = batch_size,\n",
    "                                          subset = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNIJqQt8_7by"
   },
   "outputs": [],
   "source": [
    "def ELA_CNN(input_shape=(128,128,3)):\n",
    "    X_input = Input(input_shape, name=\"X\")\n",
    "    ###################################################\n",
    "    X = Conv2D(32, (5,5), padding=\"valid\", activation=tf.nn.leaky_relu, name=\"conv1_1\")(X_input)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), name=\"max_pool1_1\")(X)\n",
    "    \n",
    "    X = Conv2D(32, (5,5), padding=\"valid\", activation=tf.nn.leaky_relu, name=\"conv1_2\")(X)\n",
    "    X = MaxPooling2D(pool_size=(2,2), strides=(2,2), name=\"max_pool1_2\")(X)\n",
    "    X = Dropout(0.25, name=\"dropout1_1\")(X)\n",
    "    ##########################################################\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(256, activation=tf.nn.leaky_relu, name=\"fc1\", kernel_regularizer=l2(0.0005), bias_regularizer=l2(0.0005))(X)\n",
    "    \n",
    "    X = Dropout(0.5, name=\"dropout2\")(X)\n",
    "    X = Dense(2, activation=\"softmax\", name=\"fc2\")(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=X_input, outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fXb7FRMP_-Pm"
   },
   "outputs": [],
   "source": [
    "model = ELA_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "Cn0nyb5rylrx",
    "outputId": "2d2ebd8a-9ded-4541-9d8b-fb9c980cce14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "X (InputLayer)               [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pool1_1 (MaxPooling2D)   (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 58, 58, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pool1_2 (MaxPooling2D)   (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout1_1 (Dropout)         (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 26912)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               6889728   \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 6,918,306\n",
      "Trainable params: 6,918,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0MDEtYJIf1x"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9, decay=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "Q33DafDYF9C1",
    "outputId": "607a94d9-66c2-4cf7-e733-6299cc8a68ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "314/314 [==============================] - 50s 158ms/step - loss: 0.6688 - accuracy: 0.6722 - val_loss: 0.6378 - val_accuracy: 0.6815\n",
      "Epoch 2/30\n",
      "314/314 [==============================] - 51s 162ms/step - loss: 0.5899 - accuracy: 0.7157 - val_loss: 0.6537 - val_accuracy: 0.6803\n",
      "Epoch 3/30\n",
      "314/314 [==============================] - 48s 152ms/step - loss: 0.5903 - accuracy: 0.7206 - val_loss: 0.6944 - val_accuracy: 0.6342\n",
      "Epoch 4/30\n",
      "314/314 [==============================] - 44s 140ms/step - loss: 0.5929 - accuracy: 0.7358 - val_loss: 0.6689 - val_accuracy: 0.6803\n",
      "Epoch 5/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.6120 - accuracy: 0.7503 - val_loss: 0.7130 - val_accuracy: 0.6671\n",
      "Epoch 6/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.6262 - accuracy: 0.7609 - val_loss: 0.7002 - val_accuracy: 0.7079\n",
      "Epoch 7/30\n",
      "314/314 [==============================] - 45s 143ms/step - loss: 0.6215 - accuracy: 0.7797 - val_loss: 0.6878 - val_accuracy: 0.7512\n",
      "Epoch 8/30\n",
      "314/314 [==============================] - 46s 145ms/step - loss: 0.6431 - accuracy: 0.7864 - val_loss: 0.6832 - val_accuracy: 0.7696\n",
      "Epoch 9/30\n",
      "314/314 [==============================] - 43s 138ms/step - loss: 0.6108 - accuracy: 0.8133 - val_loss: 0.7335 - val_accuracy: 0.7656\n",
      "Epoch 10/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.6318 - accuracy: 0.8240 - val_loss: 0.7018 - val_accuracy: 0.7825\n",
      "Epoch 11/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.6058 - accuracy: 0.8380 - val_loss: 0.7284 - val_accuracy: 0.7812\n",
      "Epoch 12/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.6047 - accuracy: 0.8529 - val_loss: 0.7329 - val_accuracy: 0.7861\n",
      "Epoch 13/30\n",
      "314/314 [==============================] - 43s 138ms/step - loss: 0.6020 - accuracy: 0.8606 - val_loss: 0.8071 - val_accuracy: 0.7400\n",
      "Epoch 14/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.6063 - accuracy: 0.8708 - val_loss: 0.8097 - val_accuracy: 0.7853\n",
      "Epoch 15/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.5867 - accuracy: 0.8810 - val_loss: 0.8684 - val_accuracy: 0.7396\n",
      "Epoch 16/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.5609 - accuracy: 0.8882 - val_loss: 0.7550 - val_accuracy: 0.8045\n",
      "Epoch 17/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.5749 - accuracy: 0.8918 - val_loss: 0.7382 - val_accuracy: 0.8033\n",
      "Epoch 18/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.5451 - accuracy: 0.9032 - val_loss: 0.7888 - val_accuracy: 0.8101\n",
      "Epoch 19/30\n",
      "314/314 [==============================] - 45s 142ms/step - loss: 0.6250 - accuracy: 0.8946 - val_loss: 0.7792 - val_accuracy: 0.8209\n",
      "Epoch 20/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.5280 - accuracy: 0.9175 - val_loss: 0.7454 - val_accuracy: 0.8253\n",
      "Epoch 21/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.6740 - accuracy: 0.8884 - val_loss: 0.7871 - val_accuracy: 0.8241\n",
      "Epoch 22/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.5270 - accuracy: 0.9216 - val_loss: 0.8001 - val_accuracy: 0.7965\n",
      "Epoch 23/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.5000 - accuracy: 0.9264 - val_loss: 0.7898 - val_accuracy: 0.8097\n",
      "Epoch 24/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.4720 - accuracy: 0.9339 - val_loss: 0.8279 - val_accuracy: 0.8037\n",
      "Epoch 25/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.4621 - accuracy: 0.9400 - val_loss: 0.7663 - val_accuracy: 0.8121\n",
      "Epoch 26/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.4812 - accuracy: 0.9336 - val_loss: 0.8123 - val_accuracy: 0.8217\n",
      "Epoch 27/30\n",
      "314/314 [==============================] - 43s 137ms/step - loss: 0.4750 - accuracy: 0.9351 - val_loss: 0.8226 - val_accuracy: 0.7993\n",
      "Epoch 28/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.4716 - accuracy: 0.9383 - val_loss: 0.8507 - val_accuracy: 0.8169\n",
      "Epoch 29/30\n",
      "314/314 [==============================] - 42s 135ms/step - loss: 0.4740 - accuracy: 0.9397 - val_loss: 0.8273 - val_accuracy: 0.8073\n",
      "Epoch 30/30\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.4699 - accuracy: 0.9431 - val_loss: 0.8214 - val_accuracy: 0.8217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x172c8223a90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath=r\"data\\checkpoints\\tampering_detection\\\\\",\n",
    "                                                               save_weights_only=True)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          batch_size=batch_size,\n",
    "          epochs=30,\n",
    "          validation_data=val_generator,\n",
    "          steps_per_epoch=10049//batch_size,\n",
    "          validation_steps=2511//batch_size\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9, decay=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "314/314 [==============================] - 49s 157ms/step - loss: 0.4193 - accuracy: 0.9577 - val_loss: 0.7904 - val_accuracy: 0.8269\n",
      "Epoch 2/10\n",
      "314/314 [==============================] - 49s 157ms/step - loss: 0.3840 - accuracy: 0.9630 - val_loss: 0.8000 - val_accuracy: 0.8225\n",
      "Epoch 3/10\n",
      "314/314 [==============================] - 47s 150ms/step - loss: 0.3579 - accuracy: 0.9681 - val_loss: 0.7778 - val_accuracy: 0.8237\n",
      "Epoch 4/10\n",
      "314/314 [==============================] - 46s 148ms/step - loss: 0.3374 - accuracy: 0.9729 - val_loss: 0.7381 - val_accuracy: 0.8365\n",
      "Epoch 5/10\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.3116 - accuracy: 0.9781 - val_loss: 0.7398 - val_accuracy: 0.8361\n",
      "Epoch 6/10\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.2931 - accuracy: 0.9796 - val_loss: 0.7584 - val_accuracy: 0.8301\n",
      "Epoch 7/10\n",
      "314/314 [==============================] - 43s 136ms/step - loss: 0.2822 - accuracy: 0.9782 - val_loss: 0.7191 - val_accuracy: 0.8305\n",
      "Epoch 8/10\n",
      "314/314 [==============================] - 48s 154ms/step - loss: 0.2656 - accuracy: 0.9828 - val_loss: 0.8086 - val_accuracy: 0.8169\n",
      "Epoch 9/10\n",
      "314/314 [==============================] - 49s 155ms/step - loss: 0.2598 - accuracy: 0.9809 - val_loss: 0.7142 - val_accuracy: 0.8466\n",
      "Epoch 10/10\n",
      "314/314 [==============================] - 49s 155ms/step - loss: 0.2464 - accuracy: 0.9825 - val_loss: 0.6997 - val_accuracy: 0.8498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1733d4d8d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath=r\"data\\checkpoints\\tampering_detection\\\\\",\n",
    "                                                               save_weights_only=True)\n",
    "\n",
    "model.fit(train_generator,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=val_generator,\n",
    "          steps_per_epoch=10049//batch_size,\n",
    "          validation_steps=2511//batch_size,\n",
    "          callbacks = [mc]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"checkpoints\\tampering_detection\\final_tampering_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "tampering_detection2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
